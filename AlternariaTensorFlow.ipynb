{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsORRiQRSWgH"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7g2i7wHsSK0l"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT_57sAoS7pA"
      },
      "source": [
        "# Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lQSygmDTS-2a"
      },
      "outputs": [],
      "source": [
        "data_dir_str = \"/content/drive/MyDrive/Alternaria\"\n",
        "data_dir = pathlib.Path(data_dir_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIXE2kJPmjw5",
        "outputId": "b1f0ec76-61ac-4adb-81b1-69c91037de54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.JPG')))\n",
        "image_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQtEf16_Umc5",
        "outputId": "0c3438bb-3736-449a-c223-70a9fc261def"
      },
      "outputs": [],
      "source": [
        "healthy = list(data_dir.glob('SANAS/*.JPG'))\n",
        "menor5 = list(data_dir.glob('MENOR A 5_/*.JPG'))\n",
        "ENTRE5a10 = list(data_dir.glob('5Y10/*.JPG'))\n",
        "ENTRE10a15 = list(data_dir.glob('10Y15/*.JPG'))\n",
        "ENTRE15a30 = list(data_dir.glob('15Y30/*.JPG'))\n",
        "mayor30 = list(data_dir.glob('MAYOR AL 30_/*.JPG'))\n",
        "print(len(healthy))\n",
        "print(len(menor5))\n",
        "print(len(ENTRE5a10))\n",
        "print(len(ENTRE10a15))\n",
        "print(len(ENTRE15a30))\n",
        "print(len(mayor30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1QBFTEUouff"
      },
      "source": [
        "# Standardize image size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o5gfQ2hak9P4"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "img_height = 200\n",
        "img_width = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfiD83-GpImZ"
      },
      "source": [
        "# Training and test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zv9MqqCulmlK",
        "outputId": "bc2b9ada-1848-4098-8ec4-b4c962a67fcf"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.15,\n",
        "  subset=\"training\",\n",
        "  seed=2022,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Owa9DYpMZo"
      },
      "source": [
        "Class names and image labeling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XYECJvnlvcR"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g91ag2OamQWv"
      },
      "outputs": [],
      "source": [
        "print(type(train_ds))\n",
        "tensor1,labels1=next(iter(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyNa1QPVmVUt"
      },
      "outputs": [],
      "source": [
        "print(tensor1)\n",
        "print(labels1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y82OAYqxpV2W"
      },
      "source": [
        "Label example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFHlPfe7msXJ"
      },
      "outputs": [],
      "source": [
        "plt.imshow(tensor1[0].numpy().astype(\"uint8\"))\n",
        "print(class_names[labels1[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lYR5kGZnA4V"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.15,\n",
        "  subset=\"validation\",\n",
        "  seed=2022,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxUlBBYGp4m-"
      },
      "source": [
        "Label example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPnSQoQTnGOT"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\")) #uint8 array de enteros sin signo de 8bits.Inicia en 0\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqCmspkYnR41"
      },
      "outputs": [],
      "source": [
        "testb, testl=next(iter(train_ds))\n",
        "print(testb.shape)\n",
        "print(testl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELxGZcYVndEv"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image),'   ', np.max(first_image))\n",
        "plt.imshow(first_image.numpy().astype(\"uint8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxliUK1un317"
      },
      "source": [
        "Dataset settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTxZHCi3n0zH"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNxUKbuKqJnJ"
      },
      "source": [
        "# Architecture of neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7UGapQroLns"
      },
      "outputs": [],
      "source": [
        "num_classes = 6\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR5r-rZHoR02"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nITpLCEoW3Q"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eshMzKyoof2m"
      },
      "outputs": [],
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnAs8PYNpVd5"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hytYt0BSqZQP"
      },
      "source": [
        "Training accuracy curve must be over validation one, if not the model could be overestimating. As well as, training loss curve must be below the validation one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM4GmNz0q3la"
      },
      "source": [
        "To use neural networks you must have a large amount of data, if this is not the case, you could increase the original dataset by rotating the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogM6Z-kcrW97"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzAlvlqrpepS"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.3),\n",
        "    layers.RandomZoom(0.3),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NePKm89DphEJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WFZ0iTsplCC"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqfxYFpPpn0d"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfmX22pCprEM"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdPmlh5HptOn"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npQ2VongsGc6"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss') #Training que tan bien se adapta el modelo a los datos de entrenamiento\n",
        "#validation que tan bien se adapta el modelo a nuevos datos\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BA2FgHVrcUh"
      },
      "source": [
        "# Neural network validation using images not used in training or testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OWzrxlVqFrV"
      },
      "outputs": [],
      "source": [
        "img1 = tf.keras.utils.load_img(\n",
        "    '/content/drive/MyDrive/Alternaria/SANAS/DSC_0900.JPG', target_size=(img_height, img_width)\n",
        ")\n",
        "img2= tf.keras.utils.load_img(\n",
        "    '/content/drive/MyDrive/Alternaria/MENOR A 5_/DSC_0817.JPG', target_size=(img_height, img_width)\n",
        ")\n",
        "img3 = tf.keras.utils.load_img(\n",
        "    '/content/drive/MyDrive/Alternaria/MAYOR AL 30_/DSC_0794.JPG', target_size=(img_height, img_width)\n",
        ")\n",
        "img4= tf.keras.utils.load_img(\n",
        "    '/content/drive/MyDrive/Alternaria/5Y10/DSC_0779.JPG', target_size=(img_height, img_width)\n",
        ")\n",
        "img5 = tf.keras.utils.load_img(\n",
        "    '/content/drive/MyDrive/Alternaria/15Y30/DSC_0887.JPG', target_size=(img_height, img_width)\n",
        ")\n",
        "img6= tf.keras.utils.load_img(\n",
        "    '/content/drive/MyDrive/Alternaria/10Y15/DSC_0899.JPG', target_size=(img_height, img_width)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmnQXblzqbcX"
      },
      "outputs": [],
      "source": [
        "img_array1 = tf.keras.utils.img_to_array(img1)\n",
        "img_array1 = tf.expand_dims(img_array1, 0)\n",
        "\n",
        "predictions = model.predict(img_array1)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeVv7nWYq-Lv"
      },
      "outputs": [],
      "source": [
        "img_array2 = tf.keras.utils.img_to_array(img2)\n",
        "img_array2 = tf.expand_dims(img_array2, 0)\n",
        "\n",
        "predictions = model.predict(img_array2)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSezmaKRrFmA"
      },
      "outputs": [],
      "source": [
        "img_array3 = tf.keras.utils.img_to_array(img3)\n",
        "img_array3 = tf.expand_dims(img_array3, 0)\n",
        "\n",
        "predictions = model.predict(img_array3)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ") #mayor al 30, acierto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A3IafFVrLY0"
      },
      "outputs": [],
      "source": [
        "img_array4 = tf.keras.utils.img_to_array(img4)\n",
        "img_array4 = tf.expand_dims(img_array4, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array4)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w1d4q-trQvJ"
      },
      "outputs": [],
      "source": [
        "img_array5 = tf.keras.utils.img_to_array(img5)\n",
        "img_array5 = tf.expand_dims(img_array5, 0)\n",
        "\n",
        "predictions = model.predict(img_array5)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJslYi0QrRBH"
      },
      "outputs": [],
      "source": [
        "img_array6 = tf.keras.utils.img_to_array(img6)\n",
        "img_array6 = tf.expand_dims(img_array6, 0)\n",
        "\n",
        "predictions = model.predict(img_array6)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
